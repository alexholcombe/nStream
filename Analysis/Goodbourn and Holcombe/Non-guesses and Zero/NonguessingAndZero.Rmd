---
title: "Goodbourn and Holcome: Proportion of efficacious SPEs = 0"
output: html_document
csl: apa.csl
bibliography: references.bib
---

```{r echo = F, message = F}
library(ggplot2)
library(mixRSVP)
library(dplyr)
library(magrittr)
library(reshape2)
library(purrr)
library(papaja)
rm(list=ls())

knitr::opts_chunk$set(fig.align = "center",
                      warning = F,
                      echo = F)

nReps = 100

rate <- 1000/12

GandHTrials <- read.csv('Data and Materials/allData.csv', stringsAsFactors = F)

###G&H fit models to data from separate streams, but we want to collapse streams and ignore the spatial information.
###So let's use the mixRSVP package to fit the collapsed data. 


twoStreamsOneTarget <- GandHTrials %>% filter(condition == 2, (exp == 'Exp2' & pool == 'Experienced Observers') | (exp == 'Exp1' & pool == 'SONA'))
```
In the second condition of Experiment 1 in @goodbourn_pseudoextinction_2015, participants viewed two RSVP streams, one of which was cued. That paper's analyses compare streams based on their spatial location and found no effect of position in this condition. However, we don't care about spatial position in our task, so we need to collapse the streams together and fit a mixture model to the responses from whatever stream was cued on a particular trial. I used the mixRSVP package for this. 

Goodbourn and Holcombe's data looked like this for a random participant

```{r echo = F, warning = F}
twoStreamsOneTarget %>%
  filter(ID == 'FJ') %>%
  mutate(stream = ifelse(stream == 1, 'Left','Right'))%>%
  ggplot(aes(x = SPE))+
  geom_histogram(binwidth = 1)+
  facet_grid(~stream)+
  theme_apa()
```

We combine the SPEs into a single, cued, stream.
```{r echo = F}
twoStreamsOneTarget %>%
  filter(ID == 'FJ') %>%
  dcast(trial+block~stream, value.var = 'SPE') %>%
  rename('One' = '1', 'Two' = '2') %>%
  mutate(SPE = ifelse(is.na(One), Two, One)) %>%
  ggplot(aes(x = SPE))+
    geom_histogram(binwidth = 1)+
    theme_apa()
```

##Parameter Estimates
```{r echo = F}

paramFiles <- list.files(
  path = '.',
  pattern = 'ParamsTwoStreamSingleCue2019.csv',
  full.names = T
  )


twoStreamsOneTargetWide <- twoStreamsOneTarget %>% #Put the observed proportions of zeros in params
    dcast(ID+trial+block~stream, value.var = 'SPE') %>%
    rename('One' = '1', 'Two' = '2') %>%
    mutate(SPE = ifelse(is.na(One), Two, One)) 

twoStreamsOneTargetWide <- twoStreamsOneTarget %>%
    dcast(ID+trial+block~stream, value.var = 'targetSP') %>%
    rename('One' = '1', 'Two' = '2') %>%
    mutate(targetSP = ifelse(is.na(One), Two, One)) %>%
    select(ID,trial, block, targetSP) %>%
    inner_join(twoStreamsOneTargetWide, by = c('ID','trial', 'block'))



if(length(paramFiles)>0){
  params <- read.csv(paramFiles[1], stringsAsFactors = F)
} else{
  
  params <- expand.grid(
    participant = unique(twoStreamsOneTarget$ID),
    exp = character(1),
    pool = character(1),
    efficacy = numeric(1),
    latency = numeric(1),
    precision = numeric(1),
    val = numeric(1),
    valGuessing = numeric(1),
    pLRtest = numeric(1),
    stringsAsFactors = F
  )
  
  
  
  for(thisParticipant in unique(twoStreamsOneTarget$ID)){
    thisExp <- twoStreamsOneTarget %>% filter(ID == thisParticipant) %>% pull(exp) %>% unique()
    
    thisPool <- twoStreamsOneTarget %>% filter(ID == thisParticipant) %>% pull(pool) %>% unique()
    
    cat('Participant', thisParticipant, 'in', thisExp, 'from the', thisPool, 'pool.                                          \r')
    
    theseTrials <- twoStreamsOneTargetWide %>% filter( #Put the SPEs in the same column, because we don't care about the stream location for this analysis
      ID == thisParticipant
    )
    
    theseParams <- theseTrials
      analyzeOneConditionDF(., 24, parameterBounds(), nReps)
    
    params %<>% mutate(
      exp = replace(exp, participant == thisParticipant, thisExp),
      pool = replace(pool, participant == thisParticipant, thisPool),
      efficacy = replace(efficacy, participant == thisParticipant, theseParams$efficacy),
      latency = replace(latency, participant == thisParticipant, theseParams$latency),
      precision = replace(precision, participant == thisParticipant, theseParams$precision),
      val = replace(val, participant == thisParticipant, theseParams$val),
      valGuessing = replace(val, participant == thisParticipant, theseParams$valGuessing),
      pLRtest = replace(pLRtest, participant == thisParticipant, theseParams$pLRtest)
    )
    
  }
  
  params %<>%
    mutate(latency = latency * rate,
           precision = precision * rate,
           pBetween = -999,
           nReps = nReps,
           date = strftime(Sys.time())
    )
  
  for(thisParticipant in params$participant){
    thisLatency <- params %>% filter(participant == thisParticipant) %>% pull(latency)
    thisPrecision <- params %>% filter(participant == thisParticipant) %>% pull(precision)
    
    cdfOne <- pnorm(rate, thisLatency, thisPrecision)
    cdfZero <- pnorm(0, thisLatency, thisPrecision)
    thisPBetween <- cdfOne - cdfZero
    params %<>% mutate(
      pBetween = replace(pBetween, participant == thisParticipant, thisPBetween)
    )
  }
  # 
  # write.csv(
  #   file = 'ParamsTwoStreamSingleCue2019.csv',
  #   x = params,
  #   row.names = F)
  # 
}
```

```{r}
params %>% 
  select(efficacy)%>%
  ggplot(aes(y = efficacy))+
  geom_violin(aes(x = 1))+
  geom_point(aes(x = 1), position = 'dodge')+
  scale_x_continuous(breaks = NULL)+
  labs(x = NULL, y = 'Efficacy')+
  theme_apa()

params %>% 
  select(latency)%>%
  ggplot(aes(y = latency))+
  geom_violin(aes(x = 1))+
  geom_point(aes(x = 1), position = 'dodge')+
  scale_x_continuous(breaks = NULL)+
  labs(x = NULL, y = 'Latency')+
  theme_apa()

params %>% 
  select(precision)%>%
  ggplot(aes(y = precision))+
  geom_violin(aes(x = 1))+
  geom_point(aes(x = 1), position = 'dodge')+
  scale_x_continuous(breaks = NULL)+
  labs(x = NULL, y = 'Precision')+
  theme_apa()
```

```{r}
params %>%
  melt(
    measure.vars = c('efficacy','latency','precision'),
    id.vars = c('participant'),
    variable.name = 'Parameter',
    value.name = 'Estimate'
  ) %>% 
  group_by(Parameter) %>%
  summarise(Mean = mean(Estimate),
            Sd = sd(Estimate)) %>%
  knitr::kable(digits = 2)
  
```

##Proportion of non-guessing distribution corresponding to SPE = 0
Here are the proportions of the nonguessing distributions from the model fits that corresponded to an SPE of 0. 

```{r echo = F}
paramsForTable <- params %>% 
  select(participant, pBetween) %>%
  rename(Participant = participant, SPEZero = pBetween)

cbind(paramsForTable[1:13,], paramsForTable[14:26,]) %>%
  knitr::kable(digits = 2)
```

All of these are less than one, which is what we want. A t-test confirms this

```{r echo = F}
t.test(x = params$pBetween,
       mu = 1, 
       alternative = 'less'
       )

params %>% 
  summarise(mean = mean(pBetween),
            sd = sd(pBetween),
            min = min(pBetween),
            max = max(pBetween))
```

And here are the nonguessing distributions, with SPE = 0 highlighted

```{r out.width='100%', fig.height=10}

densities <- params %>% #Purrr is new to me
  select(participant,latency, precision)%>% #Select the columns with the variables we want
  pmap_dfr(function(latency, precision, participant){ #For each row, compute the density over a range of milliseconds and return a dataframe
    SPE <- seq(-500,500,1)/(1000/12)
    latency <- latency/(1000/12)
    precision <- precision/(1000/12)
    data.frame(                                       #pmap_dfr iterates over multiple arguments (cells in each row) simultaneously
      participant = participant,                      #It expects a df from the function and binds the output together by row, hence _dfr (dataframe row). Perfect for ggplot
      SPE = SPE,
      density = dnorm(SPE, latency, precision),
      stringsAsFactors = F
    )
  }
  )


densities %>%
  ggplot(aes(x = SPE, y = density))+
  geom_area(aes(fill = SPE >= 0 & SPE <= 1))+
  facet_wrap(~participant, ncol = 3)+
  scale_fill_manual(labels = c('TRUE' = '0<=SPE<=1', 'FALSE' = 'SPE < 0 or SPE >1'), values = c('TRUE' = '#ffa951' , 'FALSE' = '#628093'), name = NULL)+
  scale_x_continuous(breaks = -3:3)

```

The guessing contribution to SPE = 0 is $0.042 \cdot (1 - efficacy)$. The sum of the guessing contribution at 0 and the proportion of efficacious responses at 0 does not exceed efficacy for any participant. This suggest that the SPE = 0 measure is a conservative measure of efficacy. Efficacious trials are spread over several SPEs, and SPE = 0 only corresponds to a subset of these trials. 

```{r}
params <- twoStreamsOneTargetWide %>%
    group_by(ID) %>%
    summarise(propZero = sum(SPE == 0)/n()) %>%
    rename(participant = ID)%>%
    inner_join(params, by ='participant')

guessingDistSummarise <- function(targetSP){ #get proportion of guessing at 0

  maxSPTheseData <-targetSP %>% max
  minSPTheseData <- targetSP %>% min
  minSPE <- 1 - maxSPTheseData
  maxSPE <- 24 - minSPTheseData

  xDomain <- minSPE:maxSPE
  
  guessingDist <- createGuessingDistribution(minSPE = minSPE,
                                             maxSPE = maxSPE,
                                             targetSP = targetSP,
                                             numItemsInStream = 24)
  
  return(guessingDist[xDomain==0]/sum(guessingDist))
} 

params <- twoStreamsOneTargetWide %>%
  group_by(ID) %>%
  summarise(guessingPropZero = guessingDistSummarise(targetSP)) %>%
  rename(participant= ID) %>%
  inner_join(params, by = 'participant')

params %<>%
  mutate(predictedZero = (pBetween * efficacy) + (guessingPropZero * (1-efficacy)))

params %<>% mutate(
  greaterThanEfficacy = ifelse(predictedZero > efficacy, TRUE, FALSE)
)

lm(propZero~predictedZero, data = params) %>% summary()


ggplot(params, aes(x = predictedZero, y = propZero))+
  geom_point()+
  geom_abline(intercept = 0, slope = 1)+
  geom_smooth(method = 'lm')

# params %<>% 
#   mutate(
#     predictedZero <- 
#   )
```

#Bibliography