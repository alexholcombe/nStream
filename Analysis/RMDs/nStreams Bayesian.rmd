---
title: "nStreams Analysis"
date: "5/18/2017"

author: 
  - name          : "Charles J. H. Ludowici"
    affiliation   : "1"
    corresponding : yes    # Define only one corresponding author
    address       : "USYD"
    email         : "charles.ludowici@sydney.edu.au"
  - name          : "Alex O. Holcombe"
    affiliation   : "1"

affiliation:
  - id            : "1"
    institution   : "The University of Sydney"

author_note: |
  Add complete departmental affiliations for each author here. Each new line herein must be indented, like this line.

  Enter author note here.

abstract: |
  Enter abstract here. Each new line herein must be indented, like this line.
  
keywords          : "keywords"
wordcount         : "X"

bibliography      : ["Bibtex/nStreams Bayesian.bib"]
nocite            : |
   @matsukura_does_2011

figsintext        : no
figurelist        : no
tablelist         : no
footnotelist      : no
lineno            : yes
mask              : no

class             : "man"
output            : papaja::apa6_pdf
---

```{r echo = FALSE, message=FALSE}
library(ggplot2)
library(reshape2)
library(papaja)
library(magrittr)
library(dplyr)
library(BayesFactor)

theme_set(theme_apa(base_size = 12) ) 

knitr::opts_chunk$set(
  echo = FALSE,
  warning = FALSE
  )

savePlots <- F


horizErrorBars <- function(data, var.name){
  SPEs <- data[,var.name]
  otherColumn <- colnames(data)[which(colnames(data)!=var.name & colnames(data) != 'participant' & colnames(data) != 'Parameter')]
  y = mean(data[,otherColumn], na.rm=T)
  se = sqrt(var(SPEs)/length(which(!is.na(SPEs))))
  xmin <- mean(SPEs, na.rm=T) - se
  xmax <- mean(SPEs, na.rm=T) + se
  x = mean(SPEs, na.rm=T)
  data.frame(x=x, xmin=xmin, xmax=xmax, y=y)
}

vertErrorBars <- function(data, var.name){
  SPEs <- data[,var.name]
  otherColumn <- colnames(data)[which(colnames(data)!=var.name & colnames(data) != 'participant' & colnames(data) != 'Parameter')]
  x = mean(data[,otherColumn], na.rm=T)
  se = sqrt(var(SPEs)/length(which(!is.na(SPEs))))
  ymin <- mean(SPEs, na.rm=T) - se
  ymax <- mean(SPEs, na.rm=T) + se
  y = mean(SPEs, na.rm=T)
  data.frame(x=x, ymin=ymin, ymax=ymax, y=y)
}


posterior <- function(t, N1, N2=NULL, delta, lo=-Inf, hi = Inf,
                      priorMean=0,priorSD=1) {
        N = ifelse(is.null(N2), N1, N1*N2/(N1+N2))
        df  = ifelse(is.null(N2), N1 - 1, N1 + N2 - 2)
        
        #prior and likelihood
        #prior <- function(delta) dnorm(delta, priorMean, priorSD)*as.integer(delta >= lo)*as.integer(delta <= hi) 
        prior <- function(delta) dcauchy(delta, priorMean, priorSD)*as.integer(delta >= lo)*as.integer(delta <= hi) 
        K=1/integrate(prior,lower=lo,upper=hi)[[1]]
        f=function(delta) K*prior(delta)
        
        #(The as.integer bits above just provide bounds for the prior if you want them)
      
        likelihood <- function(delta) dt(t, df, delta*sqrt(N))
        
        #marginal likelihood
        marginal <- integrate(function(x) f(x)*likelihood(x), lo, hi)[[1]]
        
        #posterior
        post <- function(x) f(x)*likelihood(x) / marginal
        return(post(delta))
}

null = 0

MMlatency <- read.csv('../../modelOutput/CSV/TGRSVP_Exp2_LatencyNorm.csv')
MMprecision <- read.csv('../../modelOutput/CSV/TGRSVP_Exp2_precisionNorm.csv')
MMefficacy <- read.csv('../../modelOutput/CSV/TGRSVP_Exp2_efficacyNorm.csv')

nStreamLatency <- data.frame(twoStreams = MMlatency$SingleLeft[MMlatency$Group == 1], eightStreams = MMlatency$SingleLeft[MMlatency$Group == 2])

nStreamPrecision <- data.frame(twoStreams = MMprecision$SingleLeft[MMprecision$Group == 1], eightStreams = MMprecision$SingleLeft[MMprecision$Group == 2])

nStreamEfficacy <- data.frame(twoStreams = MMefficacy$SingleLeft[MMefficacy$Group == 1], eightStreams = MMefficacy$SingleLeft[MMefficacy$Group == 2])

frequentistTestLatency = t.test(x = nStreamLatency$eightStreams, y=nStreamLatency$twoStreams, paired = T)
tLatency <- frequentistTestLatency$statistic[[1]]

```

The brain processes a stream of temporally noisy visual information. Several factors affect the time it takes to process a visual signal. These include: where it falls in the visual field [@poggel_visual_2004], its contrast (reference), its location relative to the spatial locus of attention [@carrasco_visual_2011] and its location in time relative to attentional events [@broadbent_detection_1987; @dux_attentional_2009]. From this sea of noisy timing data, the brain must sometimes determine when two events were simultaneous. How does this happen? In this article, we investigate the temporal distribution of percieved simultaneity between rapid events. To do so, we must use tasks where participants select a particular event from a dynamic display. Experiments using such tasks have highlighted two potential mechanisms by which the brain may achieve this aim.

Attention, the ability to prioritise stimuli for visual processing based on their kind or location, is one such mechanism. In tasks where there is uncertainty about the position of the response-relevant event, such as multiple stream RSVP [@goodbourn_pseudoextinction_2015; @holcombe_implied_2017] or visual search [@nakayama_sustained_1989], sudden stimulation at a peripheral location causes that location to be prioritised relative to the rest of the visual field. This prioritisation is evident in improved detection and identification reaction times and contrast sensitivity at that location [see @carrasco_visual_2011 for a review]. It is not under conscious control and is referred to as "exogenous" to distinguish it from more willful prioritisation (endogenous or feature-based attention). Attention facilitates the selection of object features to produce a bound percept. The most famous example of this is Treisman and Schmidt's (1982) illusory conjunctions. They demonstrated that features are mislocated when attention is overloaded in brief, static presentations. This selection can occur in dynamic displays too. Holcombe and Cavanagh (2008) presented participants with dot patterns that alternated between moving away from and towards fixation at a rate of 2.66Hz. The patterns changed colour from green to red at the same rate, but the latency between colour and motion changes was varied. The transitions between colours and motions were seen as simultaneous when the motion change preceded the colour change, consistent with previous reports (Moutoussis & Zeki, 1997; Nishida & Johnston, 2002), but this apparent lag in processing disappeared when Holcombe and Cavanagh presented an exogenous attention cue (a white ring) with the stimulus. Under this condition the relative timing between colour and motion changes that best yielded apparent synchrony was close to 0. In other words, the exogenous cue allowed participants to correctly identify when colour and motion changes were simultaneous.

This article is about temporal processing, so it is worth describing the temporal properties of an exogenous attention shift. The selection of any two events in time must happen after the onset of the cue, because the shift is triggered by the cueing stimulus. The deployment of exogenous attention seems to be most efficacious around 100-120ms after the onset of the cue and then declines [@carrasco_visual_2011; @nakayama_sustained_1989]. The time at which attention arrives at the cued position will be distributed with positive skew. The probability of completing the shift at the time of the cue's onset is zero, because this is the process that triggers the shift. The probability of completing the shift then increases rapidly, and trails off in the same manner that reaction times are distributed. This skew comes about because the process has a lower bound at the time of the cue, but no upper bound (apparently something in the Luce RT book about this) The effect of an exogenous cue on accuracy in visual search tasks yields a distribution with this shape (Nakayama & MacKeben, 1983). Our task [which I haven't explained yet] provides a measure of the arrival time of attention because the first item to be percieved is the item selected. The accuracy pattern in static tasks where SOA is varied, on the other hand, reflects arrival times and the overlap between the application of attention and the stimulus. Note that because we are concerned with selection of an event from a dynamic display, for events briefer than 100ms, the probability of selecting that event from the visual stream is low. Any distribution of selection times produced by an attention shift will thus have positive skew and be entirely post-cue.

```{r echo = FALSE}
attentionShiftExample <- data.frame(
  x = (-200):500,
  y = dlnorm(x = (-200):500, meanlog = 5, sdlog = .5)
)

ggplot(attentionShiftExample, aes(x=x,y=y))+
  geom_line()
```

@goodbourn_pseudoextinction propose that rapidly decaying buffer of visual information may be another source of information for judging simultaneity. This buffer contains decaying representations of visual events.Unlike the attention shift there is no triggering process. The buffer is always recording events. One item from the buffer is selected for tokenisation and subsequent consolidation into working memory. This is based on some task-relevant factor such as simultaneity with a cue. @goodbourn_pseudoextinction argued for the presence of this storage based on RSVP data. In each trial of their experiments participants saw 2 RSVP streams containing letters in a random order with no repeats. One or both of the streams were cued at one point on each trial with white ring. Participants were tasked with reporting the cued letter(s).  The lack of repeats allowed @goodbourn_pseudoextinction to map each response onto a point in time based on where that letter appeared in the relevant stream and build a temporal distribution of responses. After accounting for guessing (details in Modelling below), @goodbourn_pseudoextinction found that there were nonguessing responses from at the cue or before, despite the fact the cue was a white circle with a rapid onset, exactly the sort of stimulus we would expect to elicit an exogenous attention shift. These responses are impossible under an attention shift account, however they are possible if the process that selects an item for conslidation is error prone and operates over item representations from timepoints that preceded the the cue. 

The @goodbourn_pseudoextinction buffer is a brief, high-capacity store of visual information, similar to iconic memory [IM; @sperling_information_1960] and fragile memory [@sligte_are_2008]. However, it is not either of these kinds of memory. IM is a was proposed based on experiments showing that a cue presented after the offset of a brief visual array indicating a part of the array for report produces better memory for the array than without the cue. The cued information is thought to be selected from IM and sustained while the unselected information decays. Recently, another form of visual memory has been demonstrated using these cues at different timescales. This memory operates at a timepoint beyond the decay of IM and is not masked in the same way as IM [@pinto_fragile_2013; @sligte_are_2008, but see Matsukura & Hollingworth, 2011 for a dissenting opinion]. Iconic memory is extremely sensitive to masking from any stimulation at the visual location of the array. FM is not sensitive to masking from just any stimulation, but is masked by objects of the same kind at the visual location of the array (Pinto et al., 2013). @goodbourn_pseudoextinction used RSVP, where subsequent items - all of one kind - mask previous items. Under these conditions it is not possible to use IM or FM to perform the task. 

The current article uses multiple-stream RSVP investigate the temporal properties of @goodbourn_pseudoextinction's bufferas we manipulate the buffer's workload. We look for evidence of attention shifts in our data and in the initial @goodbourn_pseudoextinction data. The capacity of the buffer is unknown, as @goodbourn_pseudoextinction used a maximum of 2 RSVP streams. We increased the number of streams to 8, because this should exceed the buffer's capacity. We predicted under these conditions participants would rely on attention shifts rather than to select items from the cued stream. This strategy would produce a temporal distribution of responses that is positively skewed and entirely post-cue, whereas using buffered information for the task will create a normal distribution of responses that include timepoints from at the cue or before. We fit models corresponding to both these scenarios to detect the different strategies and interpret the estimated parameters of these models to draw inferences about the temporal properties of visual processing under these conditions. 

##Modelling

Our modelling is based on the temporal distribution of responses over many trials. We match each trial's response to a particular point in time on that trial - its serial position error (SPE). We fit distributions to the distributions of SPEs from all trials of a particular condition. The empirical RSVP distributions are thought to be a mixture of two components. One is a uniform component corresponding to trials in which the participant made a guess about the identity of the cued letter. The other component of the distribution will be responses informed by the cue. These do not have to be accurate responses. Instead, they can reflect the variance of a temporal binding process, the items selected after an attention shift, or some other process. Attention shifts and buffering predict different non-guessing distributions for the SPE distribution. If the task is performed using information from a buffer, we would expect a Gaussian distribution that includes items from at the cue or before, because the buffer may erroenously select items from before the cue as coincident with it. @goodbourn_pseudoextinction used this latter mixture to model their data, we refer to it as the buffering model. 

If, on the other hand, participants select items from the cued stream using an attention shift, the SPE distribution will have a positively skewed non-guessing component. An attention shift will not trigger until the cue is detected. Thus, we expect the non-guessing component to not include any responses from before the cue and to have positive skew. To model this, we use the log-normal distribution as the non-guessing distribution. The log-normal is a positively-skewed distribution that is only defined for values greater than 0 [^1]. This distribution thus has the skew and domain associated with an attention shift.

We fit both these models and compared them using Bayes factors. Each participant produced a distribution of SPEs in each condition and we fit the models to each of these distributions. We computed Bayes factors from the Bayesian Information Criterion for each model fit [@wagenmakers_practical_2007]. These Bayes factors are used to select the best fitting model. 

[^1]: Update: My initial reasoning was that our items would be too brief for the correct item to be selected by an attention shift, but I no longer think this is the case. The lognormal might not be the best distribution for our purposes here. 

#Methods

##Participants

`r nrow(nStreamLatency)` naive participants took part in the study in exchange for course credit. 

##Apparatus 

The experiment was controlled by a Macbook Pro running Mac OSX 10.8.5 and was programmed in Python 2.7.12 using Psychopy. Stimuli were presented on a Mitsubishi Diamond Pro 2070SB with a resolution of 1024 x 768 pixels and a refresh rate of 60Hz. Participants viewed the experiment from a distance of 57cm. To ensure that they did not break fixation, participants' right eye movements were tracked with an SR Research Eyelink 1000. 

#2 vs 8 Streams

##Latency Analyses

```{r warning=FALSE}
latencyForPlot <- melt(nStreamLatency, measure.vars = c('twoStreams','eightStreams'),variable.name = 'Condition', value.name = 'Estimate')
latencyForPlot$Participant <- ordered(rep(1:10, times = 2))

t  <- tLatency
N1 <- 10
N2 <- 10

priorMean = null
priorSD = sqrt(.5)

#examples of BF via savage-dickey ratio
#2-sided
BF10 = dcauchy(null,priorMean,priorSD) / posterior(tLatency, N1, delta=null,
                                              priorMean=priorMean,priorSD=priorSD)

#one-sided BF
BFplus = ( 2 * dcauchy(null,priorMean,priorSD) ) / posterior(tLatency, N1, delta=null, lo=0,
                                            priorMean=priorMean,priorSD=priorSD)

delta  <- seq(-2, 4, .01)

posteriorAndPriorDF <- data.frame(delta = delta, posterior = posterior(t,N1,delta=delta, priorMean=priorMean,priorSD=priorSD), prior = dcauchy(delta, priorMean,priorSD))

posteriorModeLatency <- optimize(function(delta) posterior(tLatency, N1, delta=delta, priorMean=priorMean, priorSD=priorSD), interval=c(-4,4),maximum = T)[[1]]

#This would only work for normal, we use Cauchy!
#credibleIntervalDensityLower <- mean(posteriorAndPriorDF$posterior)-sd(posteriorAndPriorDF$posterior)*1.96
#credibleIntervalDensityUpper <- mean(posteriorAndPriorDF$posterior)+sd(posteriorAndPriorDF$posterior)*1.96

latencyHorizSE <- horizErrorBars(nStreamLatency, 'twoStreams')
latencyVertSE <- vertErrorBars(nStreamLatency, 'eightStreams')

latencyPlot <- ggplot(latencyForPlot,aes(x=Condition, y=Estimate))+
  geom_violin()+
  geom_line(aes(group=Participant, colour=Participant))+
  geom_point(aes(colour=Participant), size = 3)+
  stat_summary(geom='point', fun.y = mean, position = position_dodge(.9), aes(shape = 'Means'), size = 5)+
  scale_shape_manual(NULL,breaks = 'Means', values = 23)+
  scale_colour_brewer(palette = 'Spectral')+
  labs(x='Condition',y='Estimate (ms)',title='Latency')+
  theme(plot.title = element_text(hjust=.5))


latencyScatter <- ggplot(nStreamLatency, aes(x=twoStreams, y=eightStreams))+
  geom_point(size = 4, colour = '#FCAD68')+
  lims(x=c(20,120), y=c(20,120))+
  labs(title='Latency Estimates (ms)', x = 'Two Streams', y='Eight Streams')+
  geom_errorbarh(data = latencyHorizSE, aes(x=x, xmin=xmin, xmax = xmax, y=y),inherit.aes = F, height=5)+
  geom_errorbar(data=latencyVertSE, aes(x=x, ymin=ymin,ymax=ymax, y=y), inherit.aes = F, width = 5)+
  stat_summary(geom = 'errorbar', fun.data = mean_se)+
  theme(plot.title = element_text(size=15, hjust=.5))+
  annotate('text', x=100, y=45, label = paste0('BF10 = ', round(BF10,2)))+
  annotate('text', x = 100, y=37, label = paste0('Effect size = ', round(posteriorModeLatency,2)))+
  geom_abline(intercept = 0, slope = 1,linetype='dashed')

show(latencyScatter)



latencyBayesPlot <- ggplot(posteriorAndPriorDF, aes(x=delta))+
  geom_line(aes(y=posterior, linetype = 'Posterior'))+
  geom_line(aes(y=prior, linetype = 'Prior'))+
  scale_linetype_manual(values = c('solid','dashed'),  guide = 'legend', name = NULL)+
  labs(x = expression(delta), y='Density', title = 'Latency Effect Size')
```

BF~10~ is `r round(BF10, 2)`. There is strong evidence for a difference in mean latency between the two- and eight-streams conditions. Mean latency for the two-streams condition (M = `r nStreamLatency %>% pull(twoStreams) %>% mean %>% round(2)`, SD = `r nStreamLatency %>% pull(twoStreams) %>% sd %>% round(2)`) is less than the mean latency for the eight-streams condition (M = `r nStreamLatency %>% pull(eightStreams) %>% mean %>% round(2)`, SD = `r nStreamLatency %>% pull(eightStreams) %>% sd %>% round(2)`).


The nonguessing distribution is delayed in the eight-streams relative to the two-streams condition. There appears to be some cost for increasing the number of streams. Two possible reasons for this are: an attentional cost for distributing attention over more visual space, or a cost of interference due to the increased number of items. These possibilities are theories used in the visual search literature to explain set-size effects [i.e. @palmer_set-size_1994]. This literature distinguished between perceptual effects and those that were due to attention. These theories were tested by holding the number of items constant - thus controling any perceptual effects - but cueing a number of positions as potential target locations. Support for an attentional effect is manifest whenever the effect of set size is similar to that of the pre-cueing manipulation. 

##Precision Analysis

```{r warning=FALSE}
precisionForPlot <- melt(nStreamPrecision, measure.vars = c('twoStreams','eightStreams'),variable.name = 'Condition', value.name = 'Estimate')
precisionForPlot$Participant <- ordered(rep(1:10, times = 2))


frequentistTestPrecision <- t.test(x = nStreamPrecision$eightStreams, y = nStreamPrecision$twoStreams, paired = T)
tPrecision <- frequentistTestPrecision$statistic[[1]]

t  <- tPrecision
N1 <- 10
N2 <- 10

priorMean =0
priorSD = sqrt(.5)

#examples of BF via savage-dickey ratio
#2-sided
BF10 = dcauchy(0,priorMean,priorSD) / posterior(tPrecision, N1, delta=0,
                                              priorMean=priorMean,priorSD=priorSD)

#one-sided BF
BFplus = ( 2 * dcauchy(0,priorMean,priorSD) ) / posterior(tPrecision, N1, delta=0, lo=0,
                                            priorMean=priorMean,priorSD=priorSD)

delta  <- seq(-4, 2, .01)

posteriorModePrecision <- optimize(function(delta) posterior(tPrecision, N1, delta=delta,priorMean=priorMean,priorSD=priorSD), interval=c(-4,4),maximum = T)[[1]]

posteriorAndPriorDF <- data.frame(delta = delta, posterior = posterior(t,N1,delta=delta,
                                                                       priorMean=priorMean,priorSD=priorSD), prior = dcauchy(delta, priorMean,priorSD))

posteriorModePrecision <- optimize(function(delta) posterior(tPrecision, N1, delta=delta, priorMean=priorMean, priorSD=priorSD), interval=c(-4,4),maximum = T)[[1]]


precisionPlot <- ggplot(precisionForPlot,aes(x=Condition, y=Estimate))+
  geom_violin()+
  geom_line(aes(group=Participant, colour=Participant))+
  geom_point(aes(colour=Participant),alpha=.8, size = 3)+
  stat_summary(geom='point', fun.y = mean, position = position_dodge(.9), aes(shape = 'Means'), size = 5)+
  stat_summary(geom='errorbar', fun.data = mean_se, position = position_dodge(.9), width = .1)+
  scale_shape_manual(NULL,breaks = 'Means', values = 23)+
  scale_colour_brewer(palette = 'Spectral')+
  labs(x='Condition',y='Estimate (ms)',title='Precision')+
  theme(plot.title = element_text(hjust=.5))

show(precisionPlot)

precisionHorizSE <- horizErrorBars(nStreamPrecision, 'twoStreams')
precisionVertSE <- vertErrorBars(nStreamPrecision, 'eightStreams')

precisionScatter <- ggplot(nStreamPrecision, aes(x=twoStreams, y=eightStreams, colour=ordered(1:10)))+
  geom_point(size = 4, colour = '#FCAD68')+
  geom_errorbarh(data = precisionHorizSE, aes(x=x, xmin=xmin, xmax = xmax, y=y),inherit.aes = F, height=3)+
  geom_errorbar(data=precisionVertSE, aes(x=x, ymin=ymin,ymax=ymax, y=y), inherit.aes = F, width = 3)+
  lims(x=c(40,100), y=c(40,100))+
  labs(title='Precision Estimates (ms)')+
  scale_shape_manual(breaks = 'Means', values = 3)+
  theme(plot.title = element_text(size=15, hjust=.5))+
  annotate('text', x=90, y=70, label = paste0('BF10 = ', round(BF10,2)))+
  annotate('text', x = 90, y=66, label = paste0('Effect size = ', round(posteriorModePrecision,2)))+
  geom_abline(intercept = 0, slope = 1,linetype='dashed')+
  labs(title = 'Precision (ms)', x = 'Two Streams', y = 'Eight Streams')

show(precisionScatter)

precisionBayesPlot <- ggplot(posteriorAndPriorDF, aes(x=delta))+
  geom_line(aes(y=posterior, linetype = 'Posterior'))+
  geom_line(aes(y=prior, linetype = 'Prior'))+
  scale_linetype_manual(values = c('solid','dashed'),  guide = 'legend', name = NULL)+
  labs(x = expression(delta), y='Density', title = 'Precision Effect Size')


```

Strangely, the precision of the nonguessing distribution decreases as the number of streams increases. The two-streams condition (M = `r nStreamPrecision %>% pull(twoStreams) %>% mean %>% round(2)`, SD = `r nStreamPrecision %>% pull(twoStreams) %>% sd %>% round(2)`) has more variance in the nonguessing distributions than the eight-streams conditions (M = `r nStreamPrecision %>% pull(eightStreams) %>% mean %>% round(2)`, SD = `r nStreamPrecision %>% pull(eightStreams) %>% sd %>% round(2)`; BF~10~ = `r round(BF10,2)`). In a buffering account this could be because as the number of simultaneous items increases there is less capacity to store non-simultaneous items. In an attention shift account this is harder to account for. One possible reason could be that an inability to spread attention over eight streams causes participants to rely on only exogenous attention - rather than an endo-exo mix - and the precision we're seeing here reflects the variability in arrival times for exogenous attention (check the ERP and behavioural literature for exogenous attention estimates). Again, a pre-cuing manipulation is a method for testing this hypothesis.

##Efficacy Analysis

```{r warning=FALSE}
frequentistTestEfficacy <- t.test(x = nStreamEfficacy$eightStreams, y = nStreamEfficacy$twoStreams, paired = T)
tEfficacy <- frequentistTestEfficacy$statistic[[1]]

efficacyForPlot <- melt(nStreamEfficacy, measure.vars = c('twoStreams','eightStreams'), variable.name = 'Condition',value.name = 'Estimate')
efficacyForPlot$Participant <- ordered(rep(1:10, times = 2))

t  <- tEfficacy
N1 <- 10
N2 <- 10

priorMean =0
priorSD = sqrt(.5)

#examples of BF via savage-dickey ratio
#2-sided
BF10 = dcauchy(0,priorMean,priorSD) / posterior(tEfficacy, N1, delta=0,
                                              priorMean=priorMean,priorSD=priorSD)

#one-sided BF
BFplus = ( 2 * dcauchy(0,priorMean,priorSD) ) / posterior(tEfficacy, N1, delta=0, lo=0,
                                            priorMean=priorMean,priorSD=priorSD)

BF10
BFplus

delta  <- seq(-2, 4, .01)

posteriorAndPriorDF <- data.frame(delta = delta, posterior = posterior(t,N1,delta=delta,
                                                                       priorMean=priorMean,priorSD=priorSD), prior = dcauchy(delta, priorMean,priorSD))

posteriorModeEfficacy <- optimize(function(delta) posterior(tEfficacy, N1, delta=delta,priorMean=priorMean,priorSD=priorSD), interval=c(-4,4),maximum = T)[[1]]


efficacyHorizSE <- horizErrorBars(nStreamEfficacy, 'twoStreams')
efficacyVertSE <- vertErrorBars(nStreamEfficacy, 'eightStreams')

efficacyPlot <- ggplot(efficacyForPlot, aes(x=Condition, y=Estimate))+
  geom_violin()+
  geom_line(aes(group=Participant, colour=Participant))+
  geom_point(aes(colour = Participant), size = 3)+
  labs(x='Condition',y='Estimate',title='Efficacy')+
  theme(plot.title = element_text(hjust=.5))+
  scale_colour_brewer(palette = 'Spectral')

efficacyScatter <- ggplot(nStreamEfficacy, aes(x=twoStreams, y=eightStreams, colour=ordered(1:10)))+
  geom_point(size = 4, colour = '#FCAD68')+
  lims(x=c(0,1), y=c(0,1))+
  labs(title='Efficacy Estimates [1 - P(Guess)]', x = 'Two Streams', y='Eight Streams')+
  geom_errorbarh(data = efficacyHorizSE, aes(x=x, xmin=xmin, xmax = xmax, y=y),inherit.aes = F, height=.02)+
  geom_errorbar(data=efficacyVertSE, aes(x=x, ymin=ymin,ymax=ymax, y=y), inherit.aes = F, width = .02)+
  theme(plot.title = element_text(size=15, hjust=.5))+
  annotate('text', x=.8, y=.45, label = paste0('BF10 = ', round(BF10,2)))+
  annotate('text', x = .8, y=.37, label = paste0('Effect size = ', round(posteriorModeEfficacy,2)))+
  geom_abline(intercept = 0, slope = 1,linetype='dashed')

show(efficacyScatter)

efficacyBayesPlot <- ggplot(posteriorAndPriorDF, aes(x=delta))+
  geom_line(aes(y=posterior, linetype = 'Posterior'))+
  geom_line(aes(y=prior, linetype = 'Prior'))+
  scale_linetype_manual(values = c('solid','dashed'),  guide = 'legend', name = NULL)+
  labs(x = expression(delta), y='Density', title = 'Efficacy Effect Size')


```
The Bayesian analysis for the efficacy data shows weak evidence for a lack of an effect (BF~10~ = `r round(BF10,2)`). The mean for the two-streams condition is `r nStreamEfficacy %>% pull(twoStreams) %>% mean %>% round(2)` (SD = `r nStreamEfficacy %>% pull(twoStreams) %>% sd %>% round(2)`). The mean for the eight-streams condition is `r nStreamEfficacy %>% pull(eightStreams) %>% mean %>% round(2)` (SD = `r nStreamEfficacy %>% pull(eightStreams) %>% sd %>% round(2)`).
```{r}

predictions <- data.frame(twoStreams = rnorm(1000, nStreamLatency$twoStreams[7], nStreamPrecision$twoStreams[7]), eightStreams = rnorm(1000, nStreamLatency$eightStreams[7], nStreamPrecision$eightStreams[7]))

predictions <- melt(predictions, measure.vars = c('twoStreams', 'eightStreams'), variable.name = 'Condition', value.name = 'response')

meanLatencyTwo <- mean(nStreamLatency$twoStreams)
meanLatencyEight <- mean(nStreamLatency$eightStreams)

meanPrecisionTwo <- mean(nStreamPrecision$twoStreams)
meanPrecisionEight <- mean(nStreamPrecision$eightStreams)


predictionPlot <- ggplot()+
  stat_function(data=data.frame(x=c(-400:400)/83.33), aes(x, fill = 'Two Streams'), fun = dnorm, args = list(mean = meanLatencyTwo/83.33, sd = meanPrecisionTwo/83.33), geom='area', alpha = .5)+
  stat_function(data=data.frame(x=c(-400:400)/83.33), aes(x, fill = 'Eight Streams'), fun = dnorm, args = list(mean = meanLatencyEight/83.33, sd = meanPrecisionEight/83.33), geom='area', alpha = .6)+
  scale_fill_brewer(palette = 'Set1')+
  scale_x_continuous(breaks = -3:4,limits = c(-3,4))+
  labs(x='SPE', y=NULL, fill = 'Condition', title = 'Estimated non-guessing Distributions')

predictionPlot


if(savePlots){
  ggsave(precisionPlot, file = '../Plots/precisionViolin.png', height=15, width=20,units='cm')
  ggsave(latencyPlot, file = '../Plots/latencyViolin.png', height=15, width=20,units='cm')
  ggsave(efficacyPlot, file = '../Plots/efficacyViolin.png', height=15, width=20,units='cm')
  
  ggsave(precisionScatter, file = '../Plots/precisionScatter.png', height=15, width=20,units='cm')
  ggsave(latencyScatter, file = '../Plots/latencyScatter.png', height=15, width=20,units='cm')
  ggsave(efficacyScatter, file = '../Plots/efficacyScatter.png', height=15, width=20,units='cm')
  
  
  ggsave(efficacyBayesPlot, file = '../Plots/efficacyEffectSize.png', height=15, width=20,units='cm')
  ggsave(latencyBayesPlot, file = '../Plots/latencyEffectSize.png', height=15, width=20,units='cm')
    ggsave(precisionBayesPlot, file = '../Plots/precisionEffectSize.png', height=15, width=20,units='cm')
}
```

#Precue Data
```{r message=FALSE}

null = 0

nParticipants <- 13

MMlatency <- read.csv('../../modelOutput/precueCSV/TGRSVP_Exp2_LatencyNorm.csv')
MMprecision <- read.csv('../../modelOutput/precueCSV/TGRSVP_Exp2_precisionNorm.csv')
MMefficacy <- read.csv('../../modelOutput/precueCSV/TGRSVP_Exp2_efficacyNorm.csv')

preCueLatency <- data.frame(twoStreams = MMlatency$SingleLeft[MMlatency$Group == 1], eightStreams = MMlatency$SingleLeft[MMlatency$Group == 2])

preCuePrecision <- data.frame(twoStreams = MMprecision$SingleLeft[MMprecision$Group == 1], eightStreams = MMprecision$SingleLeft[MMprecision$Group == 2])

preCueEfficacy <- data.frame(twoStreams = MMefficacy$SingleLeft[MMefficacy$Group == 1], eightStreams = MMefficacy$SingleLeft[MMefficacy$Group == 2])

frequentistTestLatency = t.test(x = preCueLatency$eightStreams, y=preCueLatency$twoStreams, paired = T)
tLatency <- frequentistTestLatency$statistic[[1]]
frequentistTestLatency
```

In this experiment, the program presented 8 streams on each trial. Prior to the onset of a trial, participants saw a circular array of hashmarks for 250ms, as in  @goodbourn_pseudoextinction, this was followed by a blank screen for 500ms, a fixation point for 1000ms and then the RSVP streams. The possible position of the cue on a trial was indicated by white rings around either two or eight streams. These mimicked the position of the streams in the first experiment's conditions. This experiment tests whether any differences between the two or eight streams conditions are due to increasing interference that scales with the number of streams - this theory predicts no difference between conditions in this experiment - or due to a cost involved in spreading attention over a larger area of visual space - this theory predicts a replication of the initial experiment's effects. 

##Latency Analyses

```{r warning=FALSE}
latencyForPlot <- melt(preCueLatency, measure.vars = c('twoStreams','eightStreams'),variable.name = 'Condition', value.name = 'Estimate')
latencyForPlot$Participant <- ordered(rep(1:nParticipants, times = 2))

t  <- tLatency
N1 <- nParticipants
N2 <- nParticipants

priorMean = null
priorSD = sqrt(.5)

#examples of BF via savage-dickey ratio
#2-sided
BF10 = dcauchy(null,priorMean,priorSD) / posterior(tLatency, N1, delta=null,
                                              priorMean=priorMean,priorSD=priorSD)

#one-sided BF
BFplus = ( 2 * dcauchy(null,priorMean,priorSD) ) / posterior(tLatency, N1, delta=null, lo=0,
                                            priorMean=priorMean,priorSD=priorSD)

delta  <- seq(-2, 4, .01)

posteriorAndPriorDF <- data.frame(delta = delta, posterior = posterior(t,N1,delta=delta, priorMean=priorMean,priorSD=priorSD), prior = dcauchy(delta, priorMean,priorSD))

posteriorModeLatency <- optimize(function(delta) posterior(tLatency, N1, delta=delta, priorMean=priorMean, priorSD=priorSD), interval=c(-4,4),maximum = T)[[1]]

#This would only work for normal, we use Cauchy!
#credibleIntervalDensityLower <- mean(posteriorAndPriorDF$posterior)-sd(posteriorAndPriorDF$posterior)*1.96
#credibleIntervalDensityUpper <- mean(posteriorAndPriorDF$posterior)+sd(posteriorAndPriorDF$posterior)*1.96


latencyPlot <- ggplot(latencyForPlot,aes(x=Condition, y=Estimate))+
  geom_violin()+
  geom_line(aes(group=Participant, colour=Participant))+
  geom_point(aes(colour=Participant), size = 3)+
  scale_colour_brewer(palette = 'Spectral')+
  labs(x='Condition',y='Estimate (ms)',title='Latency')+
  theme(plot.title = element_text(hjust=.5))


latencyScatter <- ggplot(preCueLatency, aes(x=twoStreams, y=eightStreams))+
  geom_point(size = 4, colour = '#FCAD68')+
  lims(x=c(20,220), y=c(20,220))+
  labs(title='Latency Estimates (ms)', x = 'Two Streams', y='Eight Streams')+
  theme(plot.title = element_text(size=15, hjust=.5))+
  annotate('text', x=100, y=45, label = paste0('BF10 = ', round(BF10,2)))+
  annotate('text', x = 100, y=37, label = paste0('Effect size = ', round(posteriorModeLatency,2)))+
  geom_abline(intercept = 0, slope = 1,linetype='dashed')

show(latencyScatter)



latencyBayesPlot <- ggplot(posteriorAndPriorDF, aes(x=delta))+
  geom_line(aes(y=posterior, linetype = 'Posterior'))+
  geom_line(aes(y=prior, linetype = 'Prior'))+
  scale_linetype_manual(values = c('solid','dashed'),  guide = 'legend', name = NULL)+
  labs(x = expression(delta), y='Density', title = 'Latency Effect Size')
```

The latency for the two-precues condition (M = `r preCueLatency %>% pull(twoStreams) %>% mean %>% round(2)`, SD = `r preCueLatency %>% pull(twoStreams) %>% sd %>% round(2)`) is less than that of the eight-precues condition (M = `r preCueLatency %>% pull(eightStreams) %>% mean %>% round(2)`, SD = `r preCueLatency %>% pull(eightStreams) %>% sd %>% round(2)`; BF~10~ = `r round(BF10,2)`). 

#Precision Analysis

```{r warning=FALSE}
precisionForPlot <- melt(preCuePrecision, measure.vars = c('twoStreams','eightStreams'),variable.name = 'Condition', value.name = 'Estimate')
precisionForPlot$Participant <- ordered(rep(1:nParticipants, times = 2))


frequentistTestPrecision <- t.test(x = preCuePrecision$eightStreams, y = preCuePrecision$twoStreams, paired = T)
tPrecision <- frequentistTestPrecision$statistic[[1]]

t  <- tPrecision
N1 <- nParticipants
N2 <- nParticipants

priorMean =0
priorSD = sqrt(.5)

#examples of BF via savage-dickey ratio
#2-sided
BF10 = dcauchy(0,priorMean,priorSD) / posterior(tPrecision, N1, delta=0,
                                              priorMean=priorMean,priorSD=priorSD)

#one-sided BF
BFplus = ( 2 * dcauchy(0,priorMean,priorSD) ) / posterior(tPrecision, N1, delta=0, lo=0,
                                            priorMean=priorMean,priorSD=priorSD)

BF10
BFplus

delta  <- seq(-4, 2, .01)

posteriorModePrecision <- optimize(function(delta) posterior(tPrecision, N1, delta=delta,priorMean=priorMean,priorSD=priorSD), interval=c(-4,4),maximum = T)[[1]]

posteriorAndPriorDF <- data.frame(delta = delta, posterior = posterior(t,N1,delta=delta,
                                                                       priorMean=priorMean,priorSD=priorSD), prior = dcauchy(delta, priorMean,priorSD))

posteriorModePrecision <- optimize(function(delta) posterior(tPrecision, N1, delta=delta, priorMean=priorMean, priorSD=priorSD), interval=c(-4,4),maximum = T)[[1]]


precisionPlot <- ggplot(precisionForPlot,aes(x=Condition, y=Estimate))+
  geom_violin()+
  geom_line(aes(group=Participant, colour=Participant))+
  geom_point(aes(colour=Participant),alpha=.8, size = 3)+
  scale_colour_brewer(palette = 'Spectral')+
  labs(x='Condition',y='Estimate (ms)',title='Precision')+
  theme(plot.title = element_text(hjust=.5))



precisionScatter <- ggplot(preCuePrecision, aes(x=twoStreams, y=eightStreams, colour=ordered(1:nParticipants)))+
  geom_point(size = 4, colour = '#FCAD68')+
  lims(x=c(40,200), y=c(40,200))+
  labs(title='Precision Estimates (ms)')+
  theme(plot.title = element_text(size=15, hjust=.5))+
  annotate('text', x=90, y=70, label = paste0('BF10 = ', round(BF10,2)))+
  annotate('text', x = 90, y=66, label = paste0('Effect size = ', round(posteriorModePrecision,2)))+
  geom_abline(intercept = 0, slope = 1,linetype='dashed')

show(precisionScatter)

precisionBayesPlot <- ggplot(posteriorAndPriorDF, aes(x=delta))+
  geom_line(aes(y=posterior, linetype = 'Posterior'))+
  geom_line(aes(y=prior, linetype = 'Prior'))+
  scale_linetype_manual(values = c('solid','dashed'),  guide = 'legend', name = NULL)+
  labs(x = expression(delta), y='Density', title = 'Precision Effect Size')


```

There is weak evidence for no difference between the two conditions, BF~10~ = `r round(BF10,2)`. The two-precues condition has a mean of `r preCuePrecision %>% pull(twoStreams) %>% mean %>% round(2)` (SD = `r preCuePrecision %>% pull(twoStreams) %>% sd %>% round(2)`). The eight-precues condition has a mean of `r preCuePrecision %>% pull(eightStreams) %>% mean %>% round(2)` (SD = `r preCuePrecision %>% pull(eightStreams) %>% sd %>% round(2)`).

#Efficacy Analysis

```{r warning=FALSE}
frequentistTestEfficacy <- t.test(x = preCueEfficacy$eightStreams, y = preCueEfficacy$twoStreams, paired = T)
tEfficacy <- frequentistTestEfficacy$statistic[[1]]

efficacyForPlot <- melt(preCueEfficacy, measure.vars = c('twoStreams','eightStreams'), variable.name = 'Condition',value.name = 'Estimate')
efficacyForPlot$Participant <- ordered(rep(1:nParticipants, times = 2))

t  <- tEfficacy
N1 <- nParticipants
N2 <- nParticipants

priorMean =0
priorSD = sqrt(.5)

#examples of BF via savage-dickey ratio
#2-sided
BF10 = dcauchy(0,priorMean,priorSD) / posterior(tEfficacy, N1, delta=0,
                                              priorMean=priorMean,priorSD=priorSD)

#one-sided BF
BFplus = ( 2 * dcauchy(0,priorMean,priorSD) ) / posterior(tEfficacy, N1, delta=0, lo=0,
                                            priorMean=priorMean,priorSD=priorSD)

BF10
BFplus

delta  <- seq(-2, 4, .01)

posteriorAndPriorDF <- data.frame(delta = delta, posterior = posterior(t,N1,delta=delta,
                                                                       priorMean=priorMean,priorSD=priorSD), prior = dcauchy(delta, priorMean,priorSD))

posteriorModeEfficacy <- optimize(function(delta) posterior(tEfficacy, N1, delta=delta,priorMean=priorMean,priorSD=priorSD), interval=c(-4,4),maximum = T)[[1]]


efficacyPlot <- ggplot(efficacyForPlot, aes(x=Condition, y=Estimate))+
  geom_violin()+
  geom_line(aes(group=Participant, colour=Participant))+
  geom_point(aes(colour = Participant), size = 3)+
  labs(x='Condition',y='Estimate',title='Efficacy')+
  theme(plot.title = element_text(hjust=.5))+
  scale_colour_brewer(palette = 'Spectral')


efficacyScatter <- ggplot(preCueEfficacy, aes(x=twoStreams, y=eightStreams))+
  geom_point(size = 4, colour = '#FCAD68')+
  lims(x=c(0,1), y=c(0,1))+
  labs(title='Efficacy Estimates [1 - P(Guess)]', y = 'Eight Streams', y='Eight Streams')+
  theme(plot.title = element_text(size=15, hjust=.5))+
  annotate('text', x=.8, y=.45, label = paste0('BF10 = ', round(BF10,2)))+
  annotate('text', x = .8, y=.37, label = paste0('Effect size = ', round(posteriorModeEfficacy,2)))+
  geom_abline(intercept = 0, slope = 1,linetype='dashed')

show(efficacyScatter)

efficacyBayesPlot <- ggplot(posteriorAndPriorDF, aes(x=delta))+
  geom_line(aes(y=posterior, linetype = 'Posterior'))+
  geom_line(aes(y=prior, linetype = 'Prior'))+
  scale_linetype_manual(values = c('solid','dashed'),  guide = 'legend', name = NULL)+
  labs(x = expression(delta), y='Density', title = 'Efficacy Effect Size')


```

There is weak evidence for no difference between the two conditions, BF~10~ = `r round(BF10,2)`. The two-precues condition has a mean of `r preCueEfficacy %>% pull(twoStreams) %>% mean %>% round(2)` (SD = `r preCueEfficacy %>% pull(twoStreams) %>% sd %>% round(2)`). The eight-precues condition has a mean of `r preCueEfficacy %>% pull(eightStreams) %>% mean %>% round(2)` (SD = `r preCueEfficacy %>% pull(eightStreams) %>% sd %>% round(2)`).

```{r}

preCueEfficacy$Parameter <- as.character('Efficacy')
preCueLatency$Parameter <- as.character('Latency')
preCuePrecision$Parameter <- as.character('Precision')

allParams <- rbind(preCueEfficacy,preCueLatency,preCuePrecision)

allParams <- melt(allParams, measure.vars = c('twoStreams','eightStreams'), variable.name = 'Condition',value.name = 'Estimate')

paramBar <- ggplot(allParams[!allParams$Parameter=='Efficacy',], aes(x=Parameter,y=Estimate, fill = Condition))+
  stat_summary(geom='bar', fun.y = mean, position = position_dodge(.9))+
  stat_summary(geom='errorbar', fun.data=mean_se, position = position_dodge(.9), width = .3)+
  scale_fill_brewer(palette = 'Spectral')

paramBar

predictions <- data.frame(twoStreams = rnorm(1000, preCueLatency$twoStreams[7], preCuePrecision$twoStreams[7]), eightStreams = rnorm(1000, preCueLatency$eightStreams[7], preCuePrecision$eightStreams[7]))

predictions <- melt(predictions, measure.vars = c('twoStreams', 'eightStreams'), variable.name = 'Condition', value.name = 'response')

meanLatencyTwo <- mean(preCueLatency$twoStreams)
meanLatencyEight <- mean(preCueLatency$eightStreams)

meanPrecisionTwo <- mean(preCuePrecision$twoStreams)
meanPrecisionEight <- mean(preCuePrecision$eightStreams)


predictionPlot <- ggplot()+
  stat_function(data=data.frame(x=c(-400:400)/83.33), aes(x, fill = 'Two Streams'), fun = dnorm, args = list(mean = meanLatencyTwo/83.33, sd = meanPrecisionTwo/83.33), geom='area', alpha = .5)+
  stat_function(data=data.frame(x=c(-400:400)/83.33), aes(x, fill = 'Eight Streams'), fun = dnorm, args = list(mean = meanLatencyEight/83.33, sd = meanPrecisionEight/83.33), geom='area', alpha = .6)+
  scale_fill_brewer(palette = 'Set1')+
  scale_x_continuous(breaks = -3:4,limits = c(-3,4))+
  labs(x='SPE', y=NULL, fill = 'Condition')

predictionPlot


if(savePlots){
  ggsave(precisionPlot, file = '../Plots/precisionViolin.png', height=15, width=20,units='cm')
  ggsave(latencyPlot, file = '../Plots/latencyViolin.png', height=15, width=20,units='cm')
  ggsave(efficacyPlot, file = '../Plots/efficacyViolin.png', height=15, width=20,units='cm')
  
  ggsave(precisionScatter, file = '../Plots/precisionScatter.png', height=15, width=20,units='cm')
  ggsave(latencyScatter, file = '../Plots/latencyScatter.png', height=15, width=20,units='cm')
  ggsave(efficacyScatter, file = '../Plots/efficacyScatter.png', height=15, width=20,units='cm')
  
  
  ggsave(efficacyBayesPlot, file = '../Plots/efficacyEffectSize.png', height=15, width=20,units='cm')
  ggsave(latencyBayesPlot, file = '../Plots/latencyEffectSize.png', height=15, width=20,units='cm')
    ggsave(precisionBayesPlot, file = '../Plots/precisionEffectSize.png', height=15, width=20,units='cm')
}
```

##Summary
We replicated the effect of the number of streams on latency but not precision in this experiment. The delayed latency in the eight-precue condition relative to the two-precue condition cannot be because of crowding-like interference due to the number of streams displayed because the number of streams is constant across conditions. What changes is the number of potential cue positions, and thus the number of streams that must be monitored. Our latency results are then consistent with the idea that monitoring several locations for a target is taxing for the visual system and either the detection of the target or the selection of items contingent on the target lag because of this. 

```{r}
twovEightStreamsCrossExp <- ttestBF(preCueLatency$twoStreams, nStreamLatency$eightStreams, paired = F)
twovEightStreamsCrossExp
```

@palmer_set-size_1994 argues that pre-cueing components of a visual array while holding the stimuli constant gives a measure of attentional contributions to an effect. The results of our pre-cue experiment thus suggest that the latency effect is due to an attentional effect. One candidate is a cost associated with monitoring multiple stream locations. In @hogendoorn_timing_2010 (and Huang & Pashler, which I haven't yet read), the authors distinguish between attention's ability to optimise - i.e. speed up - processing at attended sites and its ability to select features and bind them into an object. Precuing a stimulus manipulates monitoring - processing of the cue should be sped up. However a bayesian t-test of the difference in latencies between experiments in the two streams conditions yields only weak evidence, and this evidence is in favour of the null (`r twovEightStreamsCrossExp %>% .@bayesFactor %>% .$bf %>% exp %>% round(2)`).
