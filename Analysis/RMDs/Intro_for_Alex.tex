\documentclass[,man,floatsintext]{apa6}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \ifxetex
    \usepackage{mathspec}
  \else
    \usepackage{fontspec}
  \fi
  \defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\usepackage{hyperref}
\hypersetup{unicode=true,
            pdftitle={nStreams Analysis},
            pdfauthor={Charles J. H. Ludowici~\& Alex O. Holcombe},
            pdfkeywords={keywords},
            pdfborder={0 0 0},
            breaklinks=true}
\urlstyle{same}  % don't use monospace font for urls
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
\IfFileExists{parskip.sty}{%
\usepackage{parskip}
}{% else
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{0}
% Redefines (sub)paragraphs to behave more like sections
\ifx\paragraph\undefined\else
\let\oldparagraph\paragraph
\renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
\let\oldsubparagraph\subparagraph
\renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

%%% Use protect on footnotes to avoid problems with footnotes in titles
\let\rmarkdownfootnote\footnote%
\def\footnote{\protect\rmarkdownfootnote}


  \title{nStreams Analysis}
    \author{Charles J. H. Ludowici\textsuperscript{1}~\& Alex O.
Holcombe\textsuperscript{1}}
      \date{5/18/2017}

\shorttitle{SHORTTITLE}
\authornote{Add complete departmental affiliations for each author here. Each new line herein must be indented, like this line.

Enter author note here.


Correspondence concerning this article should be addressed to Charles J. H. Ludowici, USYD. E-mail: charles.ludowici@sydney.edu.au}
\affiliation{
\vspace{0.5cm}
\textsuperscript{1} The University of Sydney}
\abstract{Enter abstract here. Each new line herein must be indented, like this line.
}
\keywords{keywords\newline\indent Word count: X}
\usepackage{csquotes}
\usepackage{upgreek}
\captionsetup{font=singlespacing,justification=justified}

\usepackage{longtable}
\usepackage{lscape}
\usepackage{multirow}
\usepackage{tabularx}
\usepackage[flushleft]{threeparttable}
\usepackage{threeparttablex}

\newenvironment{lltable}{\begin{landscape}\begin{center}\begin{ThreePartTable}}{\end{ThreePartTable}\end{center}\end{landscape}}

\makeatletter
\newcommand\LastLTentrywidth{1em}
\newlength\longtablewidth
\setlength{\longtablewidth}{1in}
\newcommand{\getlongtablewidth}{\begingroup \ifcsname LT@\roman{LT@tables}\endcsname \global\longtablewidth=0pt \renewcommand{\LT@entry}[2]{\global\advance\longtablewidth by ##2\relax\gdef\LastLTentrywidth{##2}}\@nameuse{LT@\roman{LT@tables}} \fi \endgroup}


\usepackage{lineno}

\linenumbers

\usepackage{amsthm}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}{Lemma}[section]
\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]
\newtheorem{corollary}{Corollary}[section]
\newtheorem{proposition}{Proposition}[section]
\theoremstyle{definition}
\newtheorem{example}{Example}[section]
\theoremstyle{definition}
\newtheorem{exercise}{Exercise}[section]
\theoremstyle{remark}
\newtheorem*{remark}{Remark}
\newtheorem*{solution}{Solution}
\begin{document}
\maketitle

The brain processes a stream of temporally noisy visual information.
Several factors affect the time it takes to process a visual signal.
These include: where it falls in the visual field (Poggel \&
Strasburger, 2004), its contrast (reference), its location relative to
the spatial locus of attention (Carrasco, 2011) and its location in time
relative to attentional events (D. E. Broadbent \& Broadbent, 1987; Dux
\& Marois, 2009). From this sea of noisy timing data, the brain must
sometimes determine when two events were simultaneous. How does this
happen? In this article, we investigate the temporal distribution of
perceived simultaneity between rapid events. To do so, we must use tasks
where participants select a particular event from a dynamic display.
Experiments using such tasks have highlighted two potential mechanisms
by which the brain may achieve this aim.

Attention, the ability to prioritise stimuli for visual processing based
on their kind or location, is one such mechanism. In tasks where there
is uncertainty about the position of a response-relevant event, such as
visual search (Nakayama \& Mackeben, 1989), sudden stimulation at a
peripheral location causes that location to be prioritised relative to
the rest of the visual field. This prioritisation is evident in improved
detection and identification reaction times and contrast sensitivity at
that location (see Carrasco, 2011 for a review). It is not under
conscious control and is referred to as \enquote{exogenous} to
distinguish it from more willful prioritisation (endogenous or
feature-based attention).

Attention facilitates the selection of object features to produce a
bound percept. The most famous example of this is Treisman and Schmidt's
(1982) illusory conjunctions. They demonstrated that features are
mislocated when attention is overloaded in brief, static presentations.
This selection can occur in dynamic displays too. Holcombe and Cavanagh
(2008) presented participants with dot patterns that oscillated away
from and towards fixation at a rate of 2.66Hz. The patterns changed
colour from green to red at the same rate, but the latency between
colour and motion changes was varied. The transitions between colours
and motions were seen as simultaneous when the motion change preceded
the colour change, consistent with previous reports (Moutoussis \& Zeki,
1997; Nishida \& Johnston, 2002). This apparent lag in processing
disappeared when Holcombe and Cavanagh presented an exogenous attention
cue (a white ring) with the stimulus. Under this condition the relative
timing between colour and motion changes that best yielded apparent
synchrony was close to 0. In other words, the exogenous cue allowed
participants to correctly identify when colour and motion changes were
simultaneous.

This article is about temporal processing, so it is worth describing the
temporal properties of an exogenous attention shift. The selection of
any two events in time must happen after the onset of the cue, because
the shift is triggered by the cueing stimulus. The time at which
attention arrives at the cued position will be distributed with positive
skew. The probability of completing the shift at the time of the cue's
onset is zero, because this is the process that triggers the shift. The
probability of completing the shift then increases rapidly. Exogenous
attention is most efficacious around 100-120ms after the onset of the
cue (Carrasco, 2011; Nakayama \& Mackeben, 1989). Efficacy then trails
off; producing a skewed distribution much like reaction time
distributions. This skew comes about because the process has a lower
bound at the time of the cue, but no upper bound (\textbf{apparently
something in the Luce RT book about this}). The effect of an exogenous
cue on accuracy in visual search tasks yields a distribution with this
shape (Nakayama \& MacKeben, 1983). Note that because we are concerned
with selection of an event from a dynamic display, for events briefer
than 100ms, the probability of selecting that event from the visual
stream is low. Any distribution of selection times produced by an
attention shift will thus have positive skew and be entirely post-cue.

\begin{figure}
\centering
\includegraphics{Intro_for_Alex_files/figure-latex/attentionShift-1.pdf}
\caption{\label{fig:attentionShift}\label{attentionShift:figs}The predicted
distribution of times for an attention shift.}
\end{figure}

Goodbourn and Holcombe (2015) propose that a rapidly decaying buffer of
visual information may be another source of information for judging
simultaneity. This buffer contains decaying representations of visual
events. Unlike the attention shift there is no triggering process. The
buffer is always recording events. One item from the buffer is selected
for tokenisation and subsequent consolidation into working memory. This
is based on some task-relevant factor such as simultaneity with a cue.
Goodbourn and Holcombe (2015) argued for the presence of this storage
based on RSVP data. In each trial of their experiments participants saw
2 RSVP streams containing letters in a random order with no repeats. One
or both of the streams were cued at one point on each trial with white
ring. Participants were tasked with reporting the cued letter(s). They
analysed the temporal distribution of responses by mapping each response
onto a point in time corresponding to when that letter appeared in the
cued stream. After accounting for guessing (details in Modelling below),
Goodbourn and Holcombe (2015) found that there were nonguessing
responses from at the cue or before. This was despite the fact the cue
was a white circle with a rapid onset, exactly the sort of stimulus one
would expect to elicit an exogenous attention shift. Indeed, these
responses are impossible under an attention shift. They are possible if
the process that selects an item for conslidation is error prone and
operates over item representations from timepoints that preceded the the
cue. Such a process would produce a normally distribution of responses.
This distribution would include items from before the cue.

The Goodbourn and Holcombe (2015) buffer is a brief, high-capacity store
of visual information, similar to iconic memory (IM; Sperling, 1960) and
fragile memory (Sligte, Scholte, \& Lamme, 2008). However, it is not
either of these. IM is a was proposed based on experiments showing that
a cue presented after the offset of a brief visual array indicating a
part of the array for report produces better memory for the array than
without the cue. The cued information is thought to be selected from IM
and sustained while the unselected information decays. Recently, another
form of visual memory has been demonstrated using these cues at
different timescales. This memory operates at a timepoint beyond the
decay of IM and is not masked in the same way as IM (Pinto, Sligte,
Shapiro, \& Lamme, 2013; Sligte et al., 2008, but see Matsukura \&
Hollingworth, 2011 for a dissenting opinion). Iconic memory is extremely
sensitive to masking from any stimulation at the visual location of the
array. FM is not sensitive to masking from just any stimulation, but is
masked by objects of the same kind at the visual location of the array
(Pinto et al., 2013). Goodbourn and Holcombe (2015) used RSVP, where
subsequent items - all of one kind - mask previous items. Under these
conditions it is not possible to use IM or FM to perform the task.

The current article uses multiple-stream RSVP investigate the temporal
properties of Goodbourn and Holcombe (2015)'s buffer as we manipulate
the its workload. We look for evidence of attention shifts in our data
and in the initial Goodbourn and Holcombe (2015) data. The capacity of
the buffer is unknown, as Goodbourn and Holcombe (2015) used a maximum
of 2 RSVP streams. We increased the number of streams to 8, because this
should exceed the buffer's capacity. We predicted under these conditions
participants would rely on attention shifts rather than to select items
from the cued stream. This strategy would produce a temporal
distribution of responses that is positively skewed and entirely
post-cue, whereas using buffered information for the task will create a
normal distribution of responses that include timepoints from before the
cue. We fit models corresponding to both these scenarios to detect the
different strategies and interpret the estimated parameters of these
models to draw inferences about the temporal properties of visual
processing under these conditions.

\subsection{Modelling}\label{modelling}

Our modelling is based on the temporal distribution of responses over
many trials. We match each trial's response to a particular point in
time on that trial - its serial position error (SPE). We fit
distributions to the distributions of SPEs from all trials of a
particular condition. The empirical RSVP distributions are thought to be
a mixture of two components. One is a uniform component corresponding to
trials in which the participant made a guess about the identity of the
cued letter. The other component of the distribution will be responses
informed by the cue. These do not have to be accurate responses.
Instead, they can reflect the variance of a temporal binding process,
the items selected after an attention shift, or some other process.
Attention shifts and buffering predict different non-guessing
distributions for the SPE distribution. If the task is performed using
information from a buffer, we would expect a Gaussian distribution that
includes items from at the cue or before, because the buffer may
erroenously select items from before the cue as coincident with it.
Goodbourn and Holcombe (2015) used this latter mixture to model their
data, we refer to it as the buffering model.

If, on the other hand, participants select items from the cued stream
using an attention shift, the SPE distribution will have a positively
skewed non-guessing component. An attention shift will not trigger until
the cue is detected. Thus, we expect the non-guessing component to not
include any responses from before the cue and to have positive skew. To
model this, we use the log-normal distribution as the non-guessing
distribution. The log-normal is a positively-skewed distribution that is
only defined for values greater than 0.\footnote{Update: My initial
  reasoning was that our items would be too brief for the correct item
  to be selected by an attention shift, but I no longer think this is
  the case. The lognormal might not be the best distribution for our
  purposes here.} This distribution thus has the skew and domain
associated with an attention shift.

We fit both these models and compared them using Bayes factors. Each
participant produced a distribution of SPEs in each condition and we fit
the models to each of these distributions. We computed Bayes factors
from the Bayesian Information Criterion for each model fit (Wagenmakers,
2007). These Bayes factors are used to select the best fitting model.

\pagebreak

\section*{Bibliography}\label{bibliography}
\addcontentsline{toc}{section}{Bibliography}

\hypertarget{refs}{}
\hypertarget{ref-broadbent_detection_1987}{}
Broadbent, D. E., \& Broadbent, M. H. (1987). From detection to
identification: Response to multiple targets in rapid serial visual
presentation. \emph{Perception \& Psychophysics}, \emph{42}(2),
105--113.

\hypertarget{ref-carrasco_visual_2011}{}
Carrasco, M. (2011). Visual attention: The past 25 years. \emph{Vision
Research}, \emph{51}(13), 1484--1525.
doi:\href{https://doi.org/10.1016/j.visres.2011.04.012}{10.1016/j.visres.2011.04.012}

\hypertarget{ref-dux_attentional_2009}{}
Dux, P. E., \& Marois, R. (2009). The attentional blink: A review of
data and theory. \emph{Attention, Perception, \& Psychophysics},
\emph{71}(8), 1683--1700.

\hypertarget{ref-goodbourn_pseudoextinction}{}
Goodbourn, P. T., \& Holcombe, A. O. (2015). ``Pseudoextinction'':
Asymmetries in simultaneous attentional selection. \emph{Journal of
Experimental Psychology: Human Perception and Performance},
\emph{41}(2), 364. Retrieved from
\url{http://psycnet.apa.org/journals/xhp/41/2/364/}

\hypertarget{ref-matsukura_does_2011}{}
Matsukura, M., \& Hollingworth, A. (2011). Does visual short-term memory
have a high-capacity stage? \emph{Psychonomic Bulletin \& Review},
\emph{18}(6), 1098--1104.
doi:\href{https://doi.org/10.3758/s13423-011-0153-2}{10.3758/s13423-011-0153-2}

\hypertarget{ref-nakayama_sustained_1989}{}
Nakayama, K., \& Mackeben, M. (1989). Sustained and transient components
of focal visual attention. \emph{Vision Research}, \emph{29}(11),
1631--1647. Retrieved from
\url{http://www.sciencedirect.com/science/article/pii/0042698989901442}

\hypertarget{ref-pinto_fragile_2013}{}
Pinto, Y., Sligte, I. G., Shapiro, K. L., \& Lamme, V. A. (2013).
Fragile visual short-term memory is an object-based and
location-specific store. \emph{Psychonomic Bulletin \& Review},
\emph{20}(4), 732--739. Retrieved from
\url{http://link.springer.com/article/10.3758/s13423-013-0393-4}

\hypertarget{ref-poggel_visual_2004}{}
Poggel, D. A., \& Strasburger, H. (2004). Visual perception in space and
time-mapping the visual field of temporal resolution. \emph{Acta
Neurobiologiae Experimentalis}, \emph{64}(3), 427--437.

\hypertarget{ref-sligte_are_2008}{}
Sligte, I. G., Scholte, H. S., \& Lamme, V. A. F. (2008). Are There
Multiple Visual Short-Term Memory Stores? \emph{PLOS ONE}, \emph{3}(2),
e1699.
doi:\href{https://doi.org/10.1371/journal.pone.0001699}{10.1371/journal.pone.0001699}

\hypertarget{ref-sperling_information_1960}{}
Sperling, G. (1960). The information available in brief visual
presentations. \emph{Psychological Monographs: General and Applied},
\emph{74}(11), 1. Retrieved from
\url{http://psycnet.apa.org/journals/mon/74/11/1/}

\hypertarget{ref-wagenmakers_practical_2007}{}
Wagenmakers, E.-J. (2007). A practical solution to the pervasive
problems ofp values. \emph{Psychonomic Bulletin \& Review},
\emph{14}(5), 779--804.
doi:\href{https://doi.org/10.3758/BF03194105}{10.3758/BF03194105}


\end{document}
